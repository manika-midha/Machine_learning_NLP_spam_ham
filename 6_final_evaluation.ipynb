{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1449c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Final Evaluation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "152dae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score,cross_validate,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import auc,roc_curve\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_colwidth',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d6c3411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in text\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv('SMSSpamCollection.tsv',sep='\\t',header=None)\n",
    "data.columns = ['label','sms_text']\n",
    "data['label_num']= data['label'].map({'ham': 0,'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6db68257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create func to remove punctuation, tokenize, remove stopwords,stem\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def clean_text (single_sms):\n",
    "    #remove punctuation\n",
    "    new_text = ''.join([char for char in single_sms if char not in string.punctuation])\n",
    "    #tokenize sentence (will remove extra spaces as well)\n",
    "    tokens = word_tokenize(new_text.lower())\n",
    "    #remove stopwords and returned stemmed word\n",
    "    new_text = [ps.stem(word) for word in tokens if word not in stopword]\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dc4a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "\n",
    "#length of text\n",
    "def ret_len(text):\n",
    "    return len(text)- text.count(' ')\n",
    "\n",
    "data ['text_len'] = data['sms_text'].apply(ret_len)\n",
    "\n",
    "\n",
    "#% of punctuation chars in a text\n",
    "def ret_punc_per(text):\n",
    "    punc_count = 0\n",
    "    for char in text :\n",
    "        if char in string.punctuation:\n",
    "            punc_count += 1\n",
    "            \n",
    "    return round(punc_count/(len(text)- text.count(' ')),3)*100\n",
    "data['punct%'] = data['sms_text'].apply(ret_punc_per)\n",
    "\n",
    "\n",
    "#num of digits in a text\n",
    "def ret_digit_per(text):\n",
    "    digit_count = 0\n",
    "    for char in text :\n",
    "        if char.isdigit():\n",
    "            digit_count += 1\n",
    "            \n",
    "    return round(digit_count/(len(text)- text.count(' ')),3)*100\n",
    "data ['digit%'] = data['sms_text'].apply(ret_digit_per)\n",
    "\n",
    "\n",
    "#percentage of capital letters:\n",
    "def ret_upper_per(text):\n",
    "    upper_count = 0\n",
    "    for char in text :\n",
    "        if char.isupper():\n",
    "            upper_count += 1\n",
    "            \n",
    "    return round(upper_count/(len(text)- text.count(' ')),3)*100\n",
    "data['upper%'] = data['sms_text'].apply(ret_upper_per)\n",
    "\n",
    "\n",
    "def ret_url_presence(text):\n",
    "   \n",
    "    urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "    if len(urls) == 0:\n",
    "        #empty list, no url\n",
    "        return 0\n",
    "    else :\n",
    "        return 1 #text has urls\n",
    "data ['url_present'] = data['sms_text'].apply(ret_url_presence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d33d27a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data :\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['sms_text','text_len','punct%','digit%','upper%','url_present']],data['label_num'],test_size=0.20, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25e727e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create vectorised dataset : convert sms_text col to a numeric form\n",
    "\n",
    "#create vectorizer and pass clean func made above\n",
    "tfid_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfid_vect_fit = tfid_vect.fit(X_train['sms_text'])\n",
    "\n",
    "#create vectorised columns\n",
    "tfid_train = tfid_vect_fit.transform(X_train['sms_text']) #sparse matrix\n",
    "tfid_test = tfid_vect_fit.transform(X_test['sms_text']) #sparse matrix\n",
    "\n",
    "\n",
    "new_train_df = X_train[['text_len','punct%','digit%','upper%','url_present']].reset_index(drop = True)\n",
    "vect_train_df = pd.DataFrame(tfid_train.toarray()) #convert sparse matrix to array\n",
    "vect_train_df.columns = tfid_vect.get_feature_names_out() #column names will be unique words \n",
    "\n",
    "new_test_df = X_test[['text_len','punct%','digit%','upper%','url_present']].reset_index(drop = True)\n",
    "vect_test_df = pd.DataFrame(tfid_test.toarray()) #convert sparse matrix to array\n",
    "vect_test_df.columns = tfid_vect.get_feature_names_out() #column names will be unique words \n",
    "\n",
    "X_train_vect = pd.concat([new_train_df,vect_train_df],axis=1)\n",
    "X_test_vect = pd.concat([new_test_df,vect_test_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4d382d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00013726835964310226\n",
      "656\n"
     ]
    }
   ],
   "source": [
    "#find best columns for Random Forest : Select features whose importance is greater than or equal to the mean \n",
    "#of all features\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect,y_train)\n",
    "\n",
    "#SelectFromModel - select features based on importance weights\n",
    "sel_r = SelectFromModel(RandomForestClassifier(random_state=42,n_jobs=-1)) #n_estimators = 100 is default\n",
    "sel_r.fit(X_resampled, y_resampled)\n",
    "\n",
    "selected_feat_rf = X_resampled.columns[sel_r.get_support()]\n",
    "print(sel_r.threshold_) #pd.Series(rf.feature_importances_).mean()\n",
    "print(len(selected_feat_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SelectFromModel : Extract best features of given dataset according to the importance of weights. \n",
    "The SelectFromModel is a meta-estimator that determines the weight importance by comparing to the given\n",
    "threshold value.\n",
    "The threshold value to use for feature selection. Features whose importance is greater or equal are kept while the \n",
    "others are discarded. If \"median\" (resp. \"mean\"), then the ``threshold`` value is the median (resp. the mean) of the\n",
    "feature importances. A scaling factor (e.g., \"1.25*mean\") may also be used. If None and if the estimator has a \n",
    "parameter penalty set to l1, either explicitly or implicitly (e.g, Lasso), the threshold used is 1e-5.\n",
    "Otherwise, \"mean\" is used by default. \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f7d45cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is 0.27548694610595703 and Predict time is 0.020874977111816406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.99      0.90      0.94       149\n",
      "\n",
      "    accuracy                           0.99      1114\n",
      "   macro avg       0.99      0.95      0.97      1114\n",
      "weighted avg       0.99      0.99      0.99      1114\n",
      "\n",
      "0.9491462948151754\n"
     ]
    }
   ],
   "source": [
    "#Find performance metrics for Random Forest with 642 features \n",
    "\n",
    "#oversample \n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect[selected_feat_rf],y_train) #642 cols\n",
    "\n",
    "#apply model, chose best features from grid search cv\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=30,random_state=42,n_jobs=-1) #best params\n",
    "\n",
    "start = time.time()\n",
    "rf.fit(X_resampled,y_resampled)\n",
    "end = time.time()\n",
    "fit_time = end-start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = rf.predict(X_test_vect[selected_feat_rf]) #642 cols\n",
    "end = time.time()\n",
    "predict_time = end-start\n",
    "\n",
    "print(f'fit time is {fit_time} and Predict time is {predict_time}')\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(auc(fpr, tpr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a6aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebb19f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00013726835964310226\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "#calculate best features for Gradient Boosting :\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect,y_train)\n",
    "\n",
    "sel_g = SelectFromModel(GradientBoostingClassifier()) #n_estimators = 100 is default\n",
    "sel_g.fit(X_resampled, y_resampled)\n",
    "\n",
    "selected_feat_gb = X_resampled.columns[sel_g.get_support()]\n",
    "\n",
    "print(sel_g.threshold_) #pd.Series(gb.feature_importances_).mean()\n",
    "print(len(selected_feat_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e174b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is 1.0869531631469727 and Predict time is 0.0027589797973632812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       965\n",
      "           1       0.91      0.92      0.91       149\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.95      0.95      0.95      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n",
      "0.9524776576137984\n",
      "CPU times: user 1.12 s, sys: 64.1 ms, total: 1.18 s\n",
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "##verify result of gridsearch cv, use best params and features to calculate performance metrics\n",
    "\n",
    "#oversample \n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect[selected_feat_gb],y_train) #87 features\n",
    "\n",
    "#apply model\n",
    "gb = GradientBoostingClassifier(n_estimators=150,max_depth=3,learning_rate=.10) #best params\n",
    "start = time.time()\n",
    "gb.fit(X_resampled,y_resampled)\n",
    "end = time.time()\n",
    "fit_time = end-start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = gb.predict(X_test_vect[selected_feat_gb]) #87 features\n",
    "end = time.time()\n",
    "predict_time = end-start\n",
    "\n",
    "print(f'fit time is {fit_time} and Predict time is {predict_time}')\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5520f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Prediction time is more important than fit time.\n",
    "\n",
    "Interpretation :\n",
    "1) Accuracy is same for both.\n",
    "2) GB takes longer to fit\n",
    "3) RF takes longer to predict\n",
    "4) RF has a slightly higher f1 score\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
