{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d927802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score,cross_validate,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import auc,roc_curve\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_colwidth',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337d658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in text\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv('SMSSpamCollection.tsv',sep='\\t',header=None)\n",
    "data.columns = ['label','sms_text']\n",
    "data['label_num']= data['label'].map({'ham': 0,'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dbf69dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create func to remove punctuation, tokenize, remove stopwords,stem\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def clean_text (single_sms):\n",
    "    #remove punctuation\n",
    "    new_text = ''.join([char for char in single_sms if char not in string.punctuation])\n",
    "    #tokenize sentence (will remove extra spaces as well)\n",
    "    tokens = word_tokenize(new_text.lower())\n",
    "    #remove stopwords and returned stemmed word\n",
    "    new_text = [ps.stem(word) for word in tokens if word not in stopword]\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c50dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering : add colummns that might add more information\n",
    "\n",
    "#length of text\n",
    "def ret_len(text):\n",
    "    return len(text)- text.count(' ')\n",
    "\n",
    "data ['text_len'] = data['sms_text'].apply(ret_len)\n",
    "#data.head()\n",
    "\n",
    "#% of punctuation chars in a text\n",
    "def ret_punc_per(text):\n",
    "    punc_count = 0\n",
    "    for char in text :\n",
    "        if char in string.punctuation:\n",
    "            punc_count += 1\n",
    "            \n",
    "    return round(punc_count/(len(text)- text.count(' ')),3)*100\n",
    "data['punct%'] = data['sms_text'].apply(ret_punc_per)\n",
    "#data.head()\n",
    "\n",
    "#num of digits in a text\n",
    "def ret_digit_per(text):\n",
    "    digit_count = 0\n",
    "    for char in text :\n",
    "        if char.isdigit():\n",
    "            digit_count += 1\n",
    "            \n",
    "    return round(digit_count/(len(text)- text.count(' ')),3)*100\n",
    "data ['digit%'] = data['sms_text'].apply(ret_digit_per)\n",
    "#data.head() \n",
    "\n",
    "#percentage of capital letters:\n",
    "def ret_upper_per(text):\n",
    "    upper_count = 0\n",
    "    for char in text :\n",
    "        if char.isupper():\n",
    "            upper_count += 1\n",
    "            \n",
    "    return round(upper_count/(len(text)- text.count(' ')),3)*100\n",
    "data['upper%'] = data['sms_text'].apply(ret_upper_per)\n",
    "#data.head()\n",
    "\n",
    "def ret_url_presence(text):\n",
    "   \n",
    "    urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "    if len(urls) == 0:\n",
    "        #empty list, no url\n",
    "        return 0\n",
    "    else :\n",
    "        return 1 #text has urls\n",
    "data ['url_present'] = data['sms_text'].apply(ret_url_presence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ea4994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data : \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['sms_text','text_len','punct%','digit%','upper%','url_present']],data['label_num'],test_size=0.20, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19fd92b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>digit%</th>\n",
       "      <th>upper%</th>\n",
       "      <th>url_present</th>\n",
       "      <th>0</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089mi</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>...</th>\n",
       "      <th>»</th>\n",
       "      <th>é</th>\n",
       "      <th>ü</th>\n",
       "      <th>üll</th>\n",
       "      <th>–</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>…</th>\n",
       "      <th>…thank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_len  punct%  digit%  upper%  url_present    0  008704050406  0089mi  \\\n",
       "0        94     6.4     2.1     3.2            0  0.0           0.0     0.0   \n",
       "1       104     5.8     1.9     3.8            0  0.0           0.0     0.0   \n",
       "2        49     6.1     0.0     4.1            0  0.0           0.0     0.0   \n",
       "3        39     2.6     0.0     2.6            0  0.0           0.0     0.0   \n",
       "4        22     4.5     0.0     4.5            0  0.0           0.0     0.0   \n",
       "\n",
       "   0121  01223585334  ...    »    é    ü  üll    –    ‘    ’    “    …  …thank  \n",
       "0   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "1   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "2   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "3   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "4   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "\n",
       "[5 rows x 7285 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create vectorised dataset : convert sms_text col to a numeric form\n",
    "\n",
    "#create vectorizer and pass clean func made above\n",
    "tfid_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfid_vect_fit = tfid_vect.fit(X_train['sms_text'])\n",
    "\n",
    "#create vectorised columns\n",
    "tfid_train = tfid_vect_fit.transform(X_train['sms_text']) #sparse matrix\n",
    "tfid_test = tfid_vect_fit.transform(X_test['sms_text']) #sparse matrix\n",
    "\n",
    "\n",
    "new_train_df = X_train[['text_len','punct%','digit%','upper%','url_present']].reset_index(drop = True)\n",
    "vect_train_df = pd.DataFrame(tfid_train.toarray()) #convert sparse matrix to array\n",
    "vect_train_df.columns = tfid_vect.get_feature_names_out() #column names will be unique words \n",
    "\n",
    "new_test_df = X_test[['text_len','punct%','digit%','upper%','url_present']].reset_index(drop = True)\n",
    "vect_test_df = pd.DataFrame(tfid_test.toarray()) #convert sparse matrix to array\n",
    "vect_test_df.columns = tfid_vect.get_feature_names_out() #column names will be unique words \n",
    "\n",
    "X_train_vect = pd.concat([new_train_df,vect_train_df],axis=1)\n",
    "X_test_vect = pd.concat([new_test_df,vect_test_df],axis=1)\n",
    "\n",
    "X_train_vect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0052879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for all models, data should be balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8cd7434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99935191 1.         0.99870382 1.         0.99935149]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       965\n",
      "           1       0.13      1.00      0.24       149\n",
      "\n",
      "    accuracy                           0.13      1114\n",
      "   macro avg       0.57      0.50      0.12      1114\n",
      "weighted avg       0.88      0.13      0.03      1114\n",
      "\n",
      "0.5005181347150259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manikamidha/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#logistic regression : scaled and balanced data (for log reg, data should be scaled.)\n",
    "\n",
    "#pass vectorised data to the model:\n",
    "\n",
    "#resample \n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect,y_train)\n",
    "\n",
    "#scale \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_resampled)\n",
    "X_test_scaled = scaler.transform(X_test_vect)\n",
    "\n",
    "#apply model\n",
    "lr = LogisticRegression(solver = 'newton-cg')\n",
    "\n",
    "scores = cross_val_score(lr,X_train_scaled,y_resampled,cv = 5)\n",
    "print(scores) #model is stable\n",
    "\n",
    "lr.fit(X_train_scaled,y_resampled)\n",
    "\n",
    "y_pred = lr.predict(X_test_vect)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(auc(fpr, tpr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88db80e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96824368 0.97083603 0.97861309 0.977965   0.98378729]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manikamidha/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       965\n",
      "           1       0.28      0.07      0.11       149\n",
      "\n",
      "    accuracy                           0.85      1114\n",
      "   macro avg       0.57      0.52      0.51      1114\n",
      "weighted avg       0.79      0.85      0.81      1114\n",
      "\n",
      "0.5200855443891921\n"
     ]
    }
   ],
   "source": [
    "#KNN : scaled and balanced data (for Knn, data should be scaled.)\n",
    "\n",
    "#pass vectorised data to the model:\n",
    "\n",
    "#oversample \n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect,y_train)\n",
    "\n",
    "#scale \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_resampled)\n",
    "X_test_scaled = scaler.transform(X_test_vect)\n",
    "\n",
    "#apply model\n",
    "kn = KNeighborsClassifier()\n",
    "\n",
    "scores = cross_val_score(kn,X_train_scaled,y_resampled,cv = 5)\n",
    "print(scores) #model is stable\n",
    "\n",
    "kn.fit(X_train_scaled,y_resampled)\n",
    "\n",
    "y_pred = kn.predict(X_test_vect)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(auc(fpr, tpr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f69935b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99157485 0.99092677 0.99805574 0.9889825  0.99610895]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       965\n",
      "           1       0.89      0.89      0.89       149\n",
      "\n",
      "    accuracy                           0.97      1114\n",
      "   macro avg       0.94      0.94      0.94      1114\n",
      "weighted avg       0.97      0.97      0.97      1114\n",
      "\n",
      "0.9380185693918004\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree : needs balanced data , DT can scale itself\n",
    "\n",
    "#pass vectorised data to the model:\n",
    "\n",
    "#resample \n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect,y_train)\n",
    "\n",
    "#apply model\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "scores = cross_val_score(dt,X_resampled,y_resampled,cv = 5)\n",
    "print(scores) #model is stable\n",
    "\n",
    "dt.fit(X_resampled,y_resampled)\n",
    "\n",
    "y_pred = dt.predict(X_test_vect)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(auc(fpr, tpr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "757fa943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99870382 1.         0.99935191 1.         1.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.99      0.87      0.93       149\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.99      0.94      0.96      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n",
      "[[964   1]\n",
      " [ 19 130]]\n",
      "0.935723476023229\n"
     ]
    }
   ],
   "source": [
    "#Random Forest  : needs balanced data , RF can scale itself\n",
    "\n",
    "#pass vectorised data to the model:\n",
    "\n",
    "#oversample \n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect,y_train)\n",
    "\n",
    "#apply model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(rf,X_resampled,y_resampled,cv = 5)\n",
    "print(scores) #model is stable\n",
    "\n",
    "rf.fit(X_resampled,y_resampled)\n",
    "y_pred = rf.predict(X_test_vect)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(auc(fpr, tpr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf4ee7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99157485 0.9837978  0.99481529 0.98833441 0.99286641]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       965\n",
      "           1       0.93      0.91      0.92       149\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.96      0.95      0.95      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n",
      "[[954  11]\n",
      " [ 13 136]]\n",
      "0.9506763570608896\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boost  : needs balanced data , GB can scale itself\n",
    "\n",
    "#pass vectorised data to the model:\n",
    "\n",
    "#oversample \n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect,y_train)\n",
    "\n",
    "#apply model\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "scores = cross_val_score(gb,X_resampled,y_resampled,cv = 5)\n",
    "print(scores) #model is stable\n",
    "\n",
    "gb.fit(X_resampled,y_resampled)\n",
    "y_pred = gb.predict(X_test_vect)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF is top model followed closely by GB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
