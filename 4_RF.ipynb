{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a8789d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score,cross_validate,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import auc,roc_curve\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_colwidth',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a2e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in text\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv('SMSSpamCollection.tsv',sep='\\t',header=None)\n",
    "data.columns = ['label','sms_text']\n",
    "data['label_num']= data['label'].map({'ham': 0,'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8a0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create func to remove punctuation, tokenize, remove stopwords,stem\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def clean_text (single_sms):\n",
    "    #remove punctuation\n",
    "    new_text = ''.join([char for char in single_sms if char not in string.punctuation])\n",
    "    #tokenize sentence (will remove extra spaces as well)\n",
    "    tokens = word_tokenize(new_text.lower())\n",
    "    #remove stopwords and returned stemmed word\n",
    "    new_text = [ps.stem(word) for word in tokens if word not in stopword]\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca7f0b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "\n",
    "#length of text\n",
    "def ret_len(text):\n",
    "    return len(text)- text.count(' ')\n",
    "\n",
    "data ['text_len'] = data['sms_text'].apply(ret_len)\n",
    "\n",
    "#% of punctuation chars in a text\n",
    "def ret_punc_per(text):\n",
    "    punc_count = 0\n",
    "    for char in text :\n",
    "        if char in string.punctuation:\n",
    "            punc_count += 1\n",
    "            \n",
    "    return round(punc_count/(len(text)- text.count(' ')),3)*100\n",
    "data['punct%'] = data['sms_text'].apply(ret_punc_per)\n",
    "\n",
    "#num of digits in a text\n",
    "def ret_digit_per(text):\n",
    "    digit_count = 0\n",
    "    for char in text :\n",
    "        if char.isdigit():\n",
    "            digit_count += 1\n",
    "            \n",
    "    return round(digit_count/(len(text)- text.count(' ')),3)*100\n",
    "data ['digit%'] = data['sms_text'].apply(ret_digit_per)\n",
    "\n",
    "#percentage of capital letters:\n",
    "def ret_upper_per(text):\n",
    "    upper_count = 0\n",
    "    for char in text :\n",
    "        if char.isupper():\n",
    "            upper_count += 1\n",
    "            \n",
    "    return round(upper_count/(len(text)- text.count(' ')),3)*100\n",
    "data['upper%'] = data['sms_text'].apply(ret_upper_per)\n",
    "\n",
    "def ret_url_presence(text):\n",
    "   \n",
    "    urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "    if len(urls) == 0:\n",
    "        #empty list, no url\n",
    "        return 0\n",
    "    else :\n",
    "        return 1 #text has urls\n",
    "data ['url_present'] = data['sms_text'].apply(ret_url_presence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d3eb099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data :\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['sms_text','text_len','punct%','digit%','upper%','url_present']],data['label_num'],test_size=0.20, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f152ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create vectorised dataset : convert sms_text col to a numeric form\n",
    "\n",
    "#create vectorizer and pass clean func made above\n",
    "tfid_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfid_vect_fit = tfid_vect.fit(X_train['sms_text'])\n",
    "\n",
    "#create vectorised columns\n",
    "tfid_train = tfid_vect_fit.transform(X_train['sms_text']) #sparse matrix\n",
    "tfid_test = tfid_vect_fit.transform(X_test['sms_text']) #sparse matrix\n",
    "\n",
    "\n",
    "new_train_df = X_train[['text_len','punct%','digit%','upper%','url_present']].reset_index(drop = True)\n",
    "vect_train_df = pd.DataFrame(tfid_train.toarray()) #convert sparse matrix to array\n",
    "vect_train_df.columns = tfid_vect.get_feature_names_out() #column names will be unique words \n",
    "\n",
    "new_test_df = X_test[['text_len','punct%','digit%','upper%','url_present']].reset_index(drop = True)\n",
    "vect_test_df = pd.DataFrame(tfid_test.toarray()) #convert sparse matrix to array\n",
    "vect_test_df.columns = tfid_vect.get_feature_names_out() #column names will be unique words \n",
    "\n",
    "X_train_vect = pd.concat([new_train_df,vect_train_df],axis=1)\n",
    "X_test_vect = pd.concat([new_test_df,vect_test_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a77b26dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>digit%</th>\n",
       "      <th>upper%</th>\n",
       "      <th>url_present</th>\n",
       "      <th>0</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089mi</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>...</th>\n",
       "      <th>»</th>\n",
       "      <th>é</th>\n",
       "      <th>ü</th>\n",
       "      <th>üll</th>\n",
       "      <th>–</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>…</th>\n",
       "      <th>…thank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_len  punct%  digit%  upper%  url_present    0  008704050406  0089mi  \\\n",
       "0        94     6.4     2.1     3.2            0  0.0           0.0     0.0   \n",
       "1       104     5.8     1.9     3.8            0  0.0           0.0     0.0   \n",
       "2        49     6.1     0.0     4.1            0  0.0           0.0     0.0   \n",
       "3        39     2.6     0.0     2.6            0  0.0           0.0     0.0   \n",
       "4        22     4.5     0.0     4.5            0  0.0           0.0     0.0   \n",
       "\n",
       "   0121  01223585334  ...    »    é    ü  üll    –    ‘    ’    “    …  …thank  \n",
       "0   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "1   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "2   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "3   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "4   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "\n",
       "[5 rows x 7285 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6fd8e5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         0.99935191 1.         1.        ]\n",
      "fit time is 1.3946611881256104 and Prediction time is 0.08587384223937988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       1.00      0.89      0.94       149\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.99      0.94      0.97      1114\n",
      "weighted avg       0.99      0.98      0.98      1114\n",
      "\n",
      "[[965   0]\n",
      " [ 17 132]]\n",
      "0.9429530201342282\n"
     ]
    }
   ],
   "source": [
    "#Create a benchmark for comparing performance\n",
    "\n",
    "#oversample \n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect,y_train) #7285 cols\n",
    "\n",
    "#apply model\n",
    "rf = RandomForestClassifier(random_state=42,n_jobs=-1) #default setting\n",
    "\n",
    "scores = cross_val_score(rf,X_resampled,y_resampled,cv = 5)\n",
    "print(scores) #model is stable\n",
    "\n",
    "start = time.time()\n",
    "rf.fit(X_resampled,y_resampled)\n",
    "end = time.time()\n",
    "fit_time = end-start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = rf.predict(X_test_vect) #7285 cols\n",
    "end = time.time()\n",
    "pred_time = end-start\n",
    "\n",
    "print(f'fit time is {fit_time} and Prediction time is {pred_time}')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(auc(fpr, tpr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4f9bfccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013726835964310185"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This value will be used as a threshold for selecting best features.\n",
    "pd.Series(rf.feature_importances_).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e8061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Interpret : 0 = ham, 1 = spam\n",
    "    \n",
    "            Predicted vals\n",
    "                0         1\n",
    "Actual vals 0   TP (965) FN(0)\n",
    "            1   FP(17)   TN(132)\n",
    "    \n",
    "965 ham data points were correctly predicted to be ham\n",
    "132 spam data points were correctly predicted to be spam\n",
    "17 spam data points were incorrectly predicted to be ham\n",
    "0 ham data points were correctly predicted to be spam. Good. No mis-cassification\n",
    "\n",
    "for 1, spam :\n",
    "prec = 1 , when model predicted sth as spam, it turned out to be spam.\n",
    "recall = .89 , Of all sms that came to your phone, 89% were correctly put in spam folder. Balance 11% spam msgs\n",
    "went to your inbox\n",
    "accuracy = .98, Of all msgs that came to your phone, 98% of the time they were correctly identified as spam or ham.\n",
    "\n",
    "we have scope to improve recall as 11% of spam is going to our inbox. use gridsearchcv to test different \n",
    "hyperparameters and make your model more aggressive.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf9cd9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "digit%      0.159032\n",
       "text_len    0.076999\n",
       "upper%      0.061914\n",
       "call        0.027400\n",
       "free        0.020468\n",
       "claim       0.017640\n",
       "mobil       0.016691\n",
       "punct%      0.015814\n",
       "txt         0.015457\n",
       "text        0.013746\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature importance :\n",
    "\n",
    "pd.Series(rf.feature_importances_,index = X_train_vect.columns).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f423417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(rf.feature_importances_,index = X_train_vect.columns).sort_values(ascending=False).head(10).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c38bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selection :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "466780cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642\n",
      "Index(['text_len', 'punct%', 'digit%', 'upper%', 'url_present', '02070836089',\n",
      "       '02073162414', '07090201529', '078', '0800',\n",
      "       ...\n",
      "       '£150', '£2000', '£250', '£300', '£3350', '£350', '£500', '£5000',\n",
      "       '£75000', 'ü'],\n",
      "      dtype='object', length=642)\n"
     ]
    }
   ],
   "source": [
    "#Select best features : Select features whose feature importance is greater than or equal to the mean of feature\n",
    "#importance of all features.\n",
    "\n",
    "sel = SelectFromModel(RandomForestClassifier(random_state=42,n_jobs=-1)) #n_estimators = 100 is default\n",
    "sel.fit(X_resampled, y_resampled)\n",
    "\n",
    "selected_feat = X_resampled.columns[sel.get_support()]\n",
    "print(len(selected_feat))\n",
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "805713a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text_len', 'punct%', 'digit%', 'upper%', 'url_present', '0',\n",
       "       '008704050406', '0089mi', '0121', '01223585334',\n",
       "       ...\n",
       "       '»', 'é', 'ü', 'üll', '–', '‘', '’', '“', '…', '…thank'],\n",
       "      dtype='object', length=7285)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f663fd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>digit%</th>\n",
       "      <th>upper%</th>\n",
       "      <th>url_present</th>\n",
       "      <th>02070836089</th>\n",
       "      <th>02073162414</th>\n",
       "      <th>07090201529</th>\n",
       "      <th>0800</th>\n",
       "      <th>08000839402</th>\n",
       "      <th>...</th>\n",
       "      <th>£2000</th>\n",
       "      <th>£250</th>\n",
       "      <th>£350</th>\n",
       "      <th>£400</th>\n",
       "      <th>£5</th>\n",
       "      <th>£500</th>\n",
       "      <th>£5000</th>\n",
       "      <th>£75000</th>\n",
       "      <th>£800</th>\n",
       "      <th>ü</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>102</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>105</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>24</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>34</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>56</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4454 rows × 650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_len  punct%  digit%  upper%  url_present  02070836089  02073162414  \\\n",
       "0           94     6.4     2.1     3.2            0          0.0          0.0   \n",
       "1          104     5.8     1.9     3.8            0          0.0          0.0   \n",
       "2           49     6.1     0.0     4.1            0          0.0          0.0   \n",
       "3           39     2.6     0.0     2.6            0          0.0          0.0   \n",
       "4           22     4.5     0.0     4.5            0          0.0          0.0   \n",
       "...        ...     ...     ...     ...          ...          ...          ...   \n",
       "4449       102     4.9     0.0    16.7            0          0.0          0.0   \n",
       "4450       105     2.9     1.9     2.9            0          0.0          0.0   \n",
       "4451        24     8.3     0.0     8.3            0          0.0          0.0   \n",
       "4452        34     2.9     0.0     2.9            0          0.0          0.0   \n",
       "4453        56     1.8     0.0     1.8            0          0.0          0.0   \n",
       "\n",
       "      07090201529  0800  08000839402  ...  £2000  £250  £350  £400   £5  £500  \\\n",
       "0             0.0   0.0          0.0  ...    0.0   0.0   0.0   0.0  0.0   0.0   \n",
       "1             0.0   0.0          0.0  ...    0.0   0.0   0.0   0.0  0.0   0.0   \n",
       "2             0.0   0.0          0.0  ...    0.0   0.0   0.0   0.0  0.0   0.0   \n",
       "3             0.0   0.0          0.0  ...    0.0   0.0   0.0   0.0  0.0   0.0   \n",
       "4             0.0   0.0          0.0  ...    0.0   0.0   0.0   0.0  0.0   0.0   \n",
       "...           ...   ...          ...  ...    ...   ...   ...   ...  ...   ...   \n",
       "4449          0.0   0.0          0.0  ...    0.0   0.0   0.0   0.0  0.0   0.0   \n",
       "4450          0.0   0.0          0.0  ...    0.0   0.0   0.0   0.0  0.0   0.0   \n",
       "4451          0.0   0.0          0.0  ...    0.0   0.0   0.0   0.0  0.0   0.0   \n",
       "4452          0.0   0.0          0.0  ...    0.0   0.0   0.0   0.0  0.0   0.0   \n",
       "4453          0.0   0.0          0.0  ...    0.0   0.0   0.0   0.0  0.0   0.0   \n",
       "\n",
       "      £5000  £75000  £800    ü  \n",
       "0       0.0     0.0   0.0  0.0  \n",
       "1       0.0     0.0   0.0  0.0  \n",
       "2       0.0     0.0   0.0  0.0  \n",
       "3       0.0     0.0   0.0  0.0  \n",
       "4       0.0     0.0   0.0  0.0  \n",
       "...     ...     ...   ...  ...  \n",
       "4449    0.0     0.0   0.0  0.0  \n",
       "4450    0.0     0.0   0.0  0.0  \n",
       "4451    0.0     0.0   0.0  0.0  \n",
       "4452    0.0     0.0   0.0  0.0  \n",
       "4453    0.0     0.0   0.0  0.0  \n",
       "\n",
       "[4454 rows x 650 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X Train data with best features\n",
    "X_train_vect[selected_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e6771fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99935191 0.99870382 0.99935191 0.99870382 0.99935149]\n",
      "fit time is 0.27860116958618164 and Prediction time is 0.026859045028686523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.99      0.89      0.94       149\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.99      0.95      0.97      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n",
      "[[964   1]\n",
      " [ 16 133]]\n",
      "0.9457905901171889\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance of the model with 642 best features as selected above :\n",
    "\n",
    "#oversample \n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect[selected_feat],y_train) #642 cols\n",
    "\n",
    "#apply model\n",
    "rf = RandomForestClassifier(random_state=42,n_jobs=-1) #default : estimators = 100, max depth = None\n",
    "\n",
    "scores = cross_val_score(rf,X_resampled,y_resampled,cv = 5)\n",
    "print(scores) #model is stable\n",
    "\n",
    "start = time.time()\n",
    "rf.fit(X_resampled,y_resampled)\n",
    "end = time.time()\n",
    "fit_time = end - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = rf.predict(X_test_vect[selected_feat]) #642 cols\n",
    "end = time.time()\n",
    "pred_time = end - start\n",
    "\n",
    "print(f'fit time is {fit_time} and Prediction time is {pred_time}')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(auc(fpr, tpr))\n",
    "\n",
    "#Accuracy of 7285 cols is same as 642 cols.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dde3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The column with the mean_test_score is the average of the scores on the test set for all the folds\n",
    "during cross-validation.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20563979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_fit_time : Avg time it takes each model to fit\n",
    "#mean_score_time : Avg time a model takes to make a prediction on test set\n",
    "#mean_test_score : Avg accuracy on the test set\n",
    "#mean_train_score : Avg accuracy on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "17ab475e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.8 s, sys: 2.07 s, total: 17.8 s\n",
      "Wall time: 58.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.727674</td>\n",
       "      <td>0.172173</td>\n",
       "      <td>0.026390</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.985410</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.988777</td>\n",
       "      <td>0.983165</td>\n",
       "      <td>0.982022</td>\n",
       "      <td>0.985855</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.536376</td>\n",
       "      <td>0.192992</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.985410</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.988777</td>\n",
       "      <td>0.983165</td>\n",
       "      <td>0.982022</td>\n",
       "      <td>0.985855</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.306357</td>\n",
       "      <td>0.015040</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 100}</td>\n",
       "      <td>0.983165</td>\n",
       "      <td>0.991021</td>\n",
       "      <td>0.988777</td>\n",
       "      <td>0.984287</td>\n",
       "      <td>0.982022</td>\n",
       "      <td>0.985855</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.387434</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.026959</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 150}</td>\n",
       "      <td>0.984287</td>\n",
       "      <td>0.991021</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.984287</td>\n",
       "      <td>0.980899</td>\n",
       "      <td>0.985630</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.767914</td>\n",
       "      <td>0.198394</td>\n",
       "      <td>0.033137</td>\n",
       "      <td>0.007341</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>0.984287</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.983165</td>\n",
       "      <td>0.982022</td>\n",
       "      <td>0.985406</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "18       0.727674      0.172173         0.026390        0.000749   \n",
       "14       0.536376      0.192992         0.025556        0.000874   \n",
       "5        0.306357      0.015040         0.019444        0.000418   \n",
       "6        0.387434      0.014200         0.026959        0.000534   \n",
       "10       0.767914      0.198394         0.033137        0.007341   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "18            None                150   \n",
       "14              90                150   \n",
       "5               30                100   \n",
       "6               30                150   \n",
       "10              60                150   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "18  {'max_depth': None, 'n_estimators': 150}           0.985410   \n",
       "14    {'max_depth': 90, 'n_estimators': 150}           0.985410   \n",
       "5     {'max_depth': 30, 'n_estimators': 100}           0.983165   \n",
       "6     {'max_depth': 30, 'n_estimators': 150}           0.984287   \n",
       "10    {'max_depth': 60, 'n_estimators': 150}           0.984287   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "18           0.989899           0.988777           0.983165   \n",
       "14           0.989899           0.988777           0.983165   \n",
       "5            0.991021           0.988777           0.984287   \n",
       "6            0.991021           0.987654           0.984287   \n",
       "10           0.989899           0.987654           0.983165   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "18           0.982022         0.985855        0.003066                1  \n",
       "14           0.982022         0.985855        0.003066                1  \n",
       "5            0.982022         0.985855        0.003453                1  \n",
       "6            0.980899         0.985630        0.003440                4  \n",
       "10           0.982022         0.985406        0.002931                5  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#rfc, n estimator 100 is default, max_depth : None is default\n",
    "\n",
    "#Gridsearch cv : to find best combination of hyperparameters :\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42,n_jobs=-1) \n",
    "params = {\n",
    "    'n_estimators':[10,100,150,300],\n",
    "    'max_depth':[20,30,60,90,None]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(rf,params,cv=5) #,n_jobs=-1\n",
    "y_train_reset_i = y_train.reset_index(drop=True)\n",
    "gs.fit(X_train_vect[selected_feat],y_train_reset_i) #650 columns\n",
    "\n",
    "#top 5 models\n",
    "pd.DataFrame(gs.cv_results_).sort_values('mean_test_score',ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7fa50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretation :\n",
    "'''\n",
    "Accuracy is same .9885181 for estimators 300 and depths = (None,90,60,30), so estimators do not affect the\n",
    "test score.\n",
    "Time taken is close for all 4 combinations.\n",
    "\n",
    "When depth and number of estimators are reduced, 30 and 150 , accuracy increases slightly and time taken is less.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e4f91cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30, 'n_estimators': 100}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "774f40dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9858545504987453"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "29d0d242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99740765 0.99805574 0.99935191 0.99935191 0.99935149]\n",
      "fit time is 0.252147912979126 and Prediction time is 0.021510839462280273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.99      0.90      0.94       149\n",
      "\n",
      "    accuracy                           0.99      1114\n",
      "   macro avg       0.99      0.95      0.97      1114\n",
      "weighted avg       0.99      0.99      0.99      1114\n",
      "\n",
      "[[964   1]\n",
      " [ 15 134]]\n",
      "0.9491462948151754\n",
      "CPU times: user 2.13 s, sys: 253 ms, total: 2.39 s\n",
      "Wall time: 2.45 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "#verify result of gridsearch cv, use best params and features to calculate performance metrics\n",
    "\n",
    "#oversample second\n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect[selected_feat],y_train) #650 cols\n",
    "\n",
    "#apply model\n",
    "rf = RandomForestClassifier(n_estimators=100,max_depth=30,random_state=42,n_jobs=-1)\n",
    "\n",
    "scores = cross_val_score(rf,X_resampled,y_resampled,cv = 5)\n",
    "print(scores) #model is stable\n",
    "\n",
    "start = time.time()\n",
    "rf.fit(X_resampled,y_resampled)\n",
    "end = time.time()\n",
    "fit_time = end - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = rf.predict(X_test_vect[selected_feat]) #642 cols\n",
    "end = time.time()\n",
    "pred_time = end - start\n",
    "\n",
    "print(f'fit time is {fit_time} and Prediction time is {pred_time}')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(auc(fpr, tpr))\n",
    "\n",
    "#Accuracy of 7285 cols is same as 642 cols."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
