{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e84a76dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score,cross_validate,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_colwidth',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hypotheses :\n",
    "1) Spam messages tend to be longer\n",
    "2) They tend to contain more digits\n",
    "3) They tend to contain more capital letters\n",
    "4) They tend to contain more urls\n",
    "5) They tend to have more punctuations\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1160285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in text\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv('SMSSpamCollection.tsv',sep='\\t',header=None)\n",
    "data.columns = ['label','sms_text']\n",
    "data['label_num']= data['label'].map({'ham': 0,'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db5bef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create func to remove punctuation, tokenize, remove stopwords,stem\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def clean_text (single_sms):\n",
    "    #remove punctuation\n",
    "    new_text = ''.join([char for char in single_sms if char not in string.punctuation])\n",
    "    #tokenize sentence (will remove extra spaces as well)\n",
    "    tokens = word_tokenize(new_text.lower())\n",
    "    #remove stopwords and returned stemmed word\n",
    "    new_text = [ps.stem(word) for word in tokens if word not in stopword]\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71501c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_text</th>\n",
       "      <th>label_num</th>\n",
       "      <th>text_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>digit%</th>\n",
       "      <th>upper%</th>\n",
       "      <th>url_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           sms_text  label_num  \\\n",
       "0   ham  I've been searching for the right words to tha...          0   \n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1   \n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...          0   \n",
       "3   ham  Even my brother is not like to speak with me. ...          0   \n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!          0   \n",
       "\n",
       "   text_len  punct%  digit%  upper%  url_present  \n",
       "0       160     2.5     0.0     1.9            0  \n",
       "1       128     4.7    19.5     7.8            0  \n",
       "2        49     4.1     0.0     4.1            0  \n",
       "3        62     3.2     0.0     3.2            0  \n",
       "4        28     7.1     0.0    92.9            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Engineering : add colummns that might add more information\n",
    "\n",
    "#length of text\n",
    "def ret_len(text):\n",
    "    return len(text)- text.count(' ')\n",
    "\n",
    "data ['text_len'] = data['sms_text'].apply(ret_len)\n",
    "\n",
    "#% of punctuation chars in a text\n",
    "def ret_punc_per(text):\n",
    "    punc_count = 0\n",
    "    for char in text :\n",
    "        if char in string.punctuation:\n",
    "            punc_count += 1\n",
    "            \n",
    "    return round(punc_count/(len(text)- text.count(' ')),3)*100\n",
    "data['punct%'] = data['sms_text'].apply(ret_punc_per)\n",
    "\n",
    "#num of digits in a text\n",
    "def ret_digit_per(text):\n",
    "    digit_count = 0\n",
    "    for char in text :\n",
    "        if char.isdigit():\n",
    "            digit_count += 1\n",
    "            \n",
    "    return round(digit_count/(len(text)- text.count(' ')),3)*100\n",
    "data ['digit%'] = data['sms_text'].apply(ret_digit_per)\n",
    "\n",
    "#percentage of capital letters:\n",
    "def ret_upper_per(text):\n",
    "    upper_count = 0\n",
    "    for char in text :\n",
    "        if char.isupper():\n",
    "            upper_count += 1\n",
    "            \n",
    "    return round(upper_count/(len(text)- text.count(' ')),3)*100\n",
    "data['upper%'] = data['sms_text'].apply(ret_upper_per)\n",
    "\n",
    "def ret_url_presence(text):\n",
    "   \n",
    "    urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "    if len(urls) == 0:\n",
    "        #empty list, no url\n",
    "        return 0\n",
    "    else :\n",
    "        return 1 #text has urls\n",
    "data ['url_present'] = data['sms_text'].apply(ret_url_presence)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08d2b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorization :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cabe391",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['sms_text','text_len','punct%','digit%','upper%','url_present']],data['label_num'],test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a03b731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>digit%</th>\n",
       "      <th>upper%</th>\n",
       "      <th>url_present</th>\n",
       "      <th>0</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089mi</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>...</th>\n",
       "      <th>»</th>\n",
       "      <th>é</th>\n",
       "      <th>ü</th>\n",
       "      <th>üll</th>\n",
       "      <th>–</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>…</th>\n",
       "      <th>…thank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_len  punct%  digit%  upper%  url_present    0  008704050406  0089mi  \\\n",
       "0        94     6.4     2.1     3.2            0  0.0           0.0     0.0   \n",
       "1       104     5.8     1.9     3.8            0  0.0           0.0     0.0   \n",
       "2        49     6.1     0.0     4.1            0  0.0           0.0     0.0   \n",
       "3        39     2.6     0.0     2.6            0  0.0           0.0     0.0   \n",
       "4        22     4.5     0.0     4.5            0  0.0           0.0     0.0   \n",
       "\n",
       "   0121  01223585334  ...    »    é    ü  üll    –    ‘    ’    “    …  …thank  \n",
       "0   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "1   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "2   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "3   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "4   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "\n",
       "[5 rows x 7285 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create vectorizer and pass clean func made above\n",
    "tfid_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfid_vect_fit = tfid_vect.fit(X_train['sms_text'])\n",
    "\n",
    "#create vectorised columns\n",
    "tfid_train = tfid_vect_fit.transform(X_train['sms_text']) #sparse matrix\n",
    "tfid_test = tfid_vect_fit.transform(X_test['sms_text']) #sparse matrix\n",
    "\n",
    "\n",
    "new_train_df = X_train[['text_len','punct%','digit%','upper%','url_present']].reset_index(drop = True)\n",
    "vect_train_df = pd.DataFrame(tfid_train.toarray())\n",
    "vect_train_df.columns = tfid_vect.get_feature_names_out() #column names will be unique words \n",
    "\n",
    "new_test_df = X_test[['text_len','punct%','digit%','upper%','url_present']].reset_index(drop = True)\n",
    "vect_test_df = pd.DataFrame(tfid_test.toarray())\n",
    "vect_test_df.columns = tfid_vect.get_feature_names_out() #column names will be unique words \n",
    "\n",
    "X_train_vect = pd.concat([new_train_df,vect_train_df],axis=1)\n",
    "X_test_vect = pd.concat([new_test_df,vect_test_df],axis=1)\n",
    "\n",
    "X_train_vect.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d58403c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4454, 7285)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
