{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead57249",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "check performance of all models - all features vs. digit%(most important feature)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "612a4a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score,cross_validate,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import auc,roc_curve\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_colwidth',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea50bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in text\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv('SMSSpamCollection.tsv',sep='\\t',header=None)\n",
    "data.columns = ['label','sms_text']\n",
    "data['label_num']= data['label'].map({'ham': 0,'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "469cb750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create func to remove punctuation, tokenize, remove stopwords,stem\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def clean_text (single_sms):\n",
    "    #remove punctuation\n",
    "    new_text = ''.join([char for char in single_sms if char not in string.punctuation])\n",
    "    #tokenize sentence (will remove extra spaces as well)\n",
    "    tokens = word_tokenize(new_text.lower())\n",
    "    #remove stopwords and returned stemmed word\n",
    "    new_text = [ps.stem(word) for word in tokens if word not in stopword]\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c38324fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "\n",
    "#length of text\n",
    "def ret_len(text):\n",
    "    return len(text)- text.count(' ')\n",
    "\n",
    "data ['text_len'] = data['sms_text'].apply(ret_len)\n",
    "\n",
    "\n",
    "#% of punctuation chars in a text\n",
    "def ret_punc_per(text):\n",
    "    punc_count = 0\n",
    "    for char in text :\n",
    "        if char in string.punctuation:\n",
    "            punc_count += 1\n",
    "            \n",
    "    return round(punc_count/(len(text)- text.count(' ')),3)*100\n",
    "data['punct%'] = data['sms_text'].apply(ret_punc_per)\n",
    "\n",
    "\n",
    "#num of digits in a text\n",
    "def ret_digit_per(text):\n",
    "    digit_count = 0\n",
    "    for char in text :\n",
    "        if char.isdigit():\n",
    "            digit_count += 1\n",
    "            \n",
    "    return round(digit_count/(len(text)- text.count(' ')),3)*100\n",
    "data ['digit%'] = data['sms_text'].apply(ret_digit_per)\n",
    "\n",
    "\n",
    "#percentage of capital letters:\n",
    "def ret_upper_per(text):\n",
    "    upper_count = 0\n",
    "    for char in text :\n",
    "        if char.isupper():\n",
    "            upper_count += 1\n",
    "            \n",
    "    return round(upper_count/(len(text)- text.count(' ')),3)*100\n",
    "data['upper%'] = data['sms_text'].apply(ret_upper_per)\n",
    "\n",
    "\n",
    "def ret_url_presence(text):\n",
    "   \n",
    "    urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "    if len(urls) == 0:\n",
    "        #empty list, no url\n",
    "        return 0\n",
    "    else :\n",
    "        return 1 #text has urls\n",
    "data ['url_present'] = data['sms_text'].apply(ret_url_presence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f99611dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data :\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['sms_text','text_len','punct%','digit%','upper%','url_present']],data['label_num'],test_size=0.20, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e1fa7c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>digit%</th>\n",
       "      <th>upper%</th>\n",
       "      <th>url_present</th>\n",
       "      <th>0</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089mi</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>...</th>\n",
       "      <th>»</th>\n",
       "      <th>é</th>\n",
       "      <th>ü</th>\n",
       "      <th>üll</th>\n",
       "      <th>–</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>…</th>\n",
       "      <th>…thank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>11.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_len  punct%  digit%  upper%  url_present    0  008704050406  0089mi  \\\n",
       "0       128     7.8     6.2    13.3            0  0.0           0.0     0.0   \n",
       "1        41     2.4     0.0     4.9            0  0.0           0.0     0.0   \n",
       "2        34    11.8     5.9     5.9            0  0.0           0.0     0.0   \n",
       "3        35     5.7     0.0     2.9            0  0.0           0.0     0.0   \n",
       "4        41     2.4     0.0     4.9            0  0.0           0.0     0.0   \n",
       "\n",
       "   0121  01223585334  ...    »    é    ü  üll    –    ‘    ’    “    …  …thank  \n",
       "0   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "1   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "2   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "3   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "4   0.0          0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  \n",
       "\n",
       "[5 rows x 7285 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create vectorised dataset : convert sms_text col to a numeric form\n",
    "\n",
    "#create vectorizer and pass clean func made above\n",
    "tfid_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfid_vect_fit = tfid_vect.fit(X_train['sms_text'])\n",
    "\n",
    "#create vectorised columns\n",
    "tfid_train = tfid_vect_fit.transform(X_train['sms_text']) #sparse matrix\n",
    "tfid_test = tfid_vect_fit.transform(X_test['sms_text']) #sparse matrix\n",
    "\n",
    "\n",
    "new_train_df = X_train[['text_len','punct%','digit%','upper%','url_present']].reset_index(drop = True)\n",
    "vect_train_df = pd.DataFrame(tfid_train.toarray()) #convert sparse matrix to array\n",
    "vect_train_df.columns = tfid_vect.get_feature_names_out() #column names will be unique words \n",
    "\n",
    "new_test_df = X_test[['text_len','punct%','digit%','upper%','url_present']].reset_index(drop = True)\n",
    "vect_test_df = pd.DataFrame(tfid_test.toarray()) #convert sparse matrix to array\n",
    "vect_test_df.columns = tfid_vect.get_feature_names_out() #column names will be unique words \n",
    "\n",
    "X_train_vect = pd.concat([new_train_df,vect_train_df],axis=1)\n",
    "X_test_vect = pd.concat([new_test_df,vect_test_df],axis=1)\n",
    "\n",
    "X_test_vect.shape\n",
    "X_test_vect.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare performance with digit% column only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b3bebe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is 29.46201205253601 and Predict time is 0.1508159637451172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       965\n",
      "           1       0.90      0.92      0.91       149\n",
      "\n",
      "    accuracy                           0.97      1114\n",
      "   macro avg       0.94      0.95      0.95      1114\n",
      "weighted avg       0.98      0.97      0.98      1114\n",
      "\n",
      "0.9514413881837466\n",
      "CPU times: user 30.2 s, sys: 1.24 s, total: 31.4 s\n",
      "Wall time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#GB with all features :\n",
    "\n",
    "#oversample \n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect,y_train) #all 7285 features\n",
    "\n",
    "#apply model\n",
    "gb = GradientBoostingClassifier() #default parameters\n",
    "start = time.time()\n",
    "gb.fit(X_resampled,y_resampled)\n",
    "end = time.time()\n",
    "fit_time = end-start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = gb.predict(X_test_vect) #all 7285 features \n",
    "end = time.time()\n",
    "predict_time = end-start\n",
    "\n",
    "print(f'fit time is {fit_time} and Predict time is {predict_time}')\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f18aea0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is 0.19907808303833008 and Predict time is 0.0008518695831298828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       965\n",
      "           1       0.73      0.87      0.80       149\n",
      "\n",
      "    accuracy                           0.94      1114\n",
      "   macro avg       0.86      0.91      0.88      1114\n",
      "weighted avg       0.95      0.94      0.94      1114\n",
      "\n",
      "0.9118892791320373\n",
      "CPU times: user 209 ms, sys: 2.91 ms, total: 211 ms\n",
      "Wall time: 209 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#GB with only digit% feature :\n",
    "\n",
    "#https://stackoverflow.com/questions/51150153/valueerror-expected-2d-array-got-1d-array-instead\n",
    "#https://www.edureka.co/community/66401/valueerror-expected-2d-array-got-1d-array-instead-array-4-7-9\n",
    "X_train_vect_digit = X_train_vect['digit%'].values.reshape(-1,1)\n",
    "X_test_vect_digit = X_test_vect['digit%'].values.reshape(-1,1)\n",
    "\n",
    "#oversample \n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect_digit,y_train)\n",
    "\n",
    "#apply model\n",
    "gb = GradientBoostingClassifier() #default parameters\n",
    "start = time.time()\n",
    "gb.fit(X_resampled,y_resampled)\n",
    "end = time.time()\n",
    "fit_time = end-start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = gb.predict(X_test_vect_digit) #only 1 feature - digit%\n",
    "end = time.time()\n",
    "predict_time = end-start\n",
    "\n",
    "print(f'fit time is {fit_time} and Predict time is {predict_time}')\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(auc(fpr, tpr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "26557627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is 0.25598978996276855 and Predict time is 0.008738040924072266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       965\n",
      "           1       0.76      0.84      0.80       149\n",
      "\n",
      "    accuracy                           0.94      1114\n",
      "   macro avg       0.87      0.90      0.88      1114\n",
      "weighted avg       0.95      0.94      0.94      1114\n",
      "\n",
      "0.8992558333623117\n",
      "CPU times: user 272 ms, sys: 4.28 ms, total: 276 ms\n",
      "Wall time: 274 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#RF with only digit% feature :\n",
    "\n",
    "#https://stackoverflow.com/questions/51150153/valueerror-expected-2d-array-got-1d-array-instead\n",
    "#https://www.edureka.co/community/66401/valueerror-expected-2d-array-got-1d-array-instead-array-4-7-9\n",
    "X_train_vect_digit = X_train_vect['digit%'].values.reshape(-1,1)\n",
    "X_test_vect_digit = X_test_vect['digit%'].values.reshape(-1,1)\n",
    "\n",
    "#oversample \n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect_digit,y_train)\n",
    "\n",
    "#apply model\n",
    "rf = RandomForestClassifier() #default parameters\n",
    "start = time.time()\n",
    "rf.fit(X_resampled,y_resampled)\n",
    "end = time.time()\n",
    "fit_time = end-start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = rf.predict(X_test_vect_digit) #only 1 feature - digit%\n",
    "end = time.time()\n",
    "predict_time = end-start\n",
    "\n",
    "print(f'fit time is {fit_time} and Predict time is {predict_time}')\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(auc(fpr, tpr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "07ec3ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is 0.006953001022338867 and Predict time is 0.0003151893615722656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       965\n",
      "           1       0.76      0.84      0.80       149\n",
      "\n",
      "    accuracy                           0.94      1114\n",
      "   macro avg       0.87      0.90      0.88      1114\n",
      "weighted avg       0.95      0.94      0.94      1114\n",
      "\n",
      "0.8987376986472858\n",
      "CPU times: user 21 ms, sys: 2.5 ms, total: 23.5 ms\n",
      "Wall time: 21.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#DT with only digit% feature :\n",
    "\n",
    "#https://stackoverflow.com/questions/51150153/valueerror-expected-2d-array-got-1d-array-instead\n",
    "#https://www.edureka.co/community/66401/valueerror-expected-2d-array-got-1d-array-instead-array-4-7-9\n",
    "X_train_vect_digit = X_train_vect['digit%'].values.reshape(-1,1)\n",
    "X_test_vect_digit = X_test_vect['digit%'].values.reshape(-1,1)\n",
    "\n",
    "#oversample \n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_vect_digit,y_train)\n",
    "\n",
    "#apply model\n",
    "dt = DecisionTreeClassifier() #default parameters\n",
    "start = time.time()\n",
    "dt.fit(X_resampled,y_resampled)\n",
    "end = time.time()\n",
    "fit_time = end-start\n",
    "\n",
    "start = time.time()\n",
    "y_pred = dt.predict(X_test_vect_digit) #only 1 feature - digit%\n",
    "end = time.time()\n",
    "predict_time = end-start\n",
    "\n",
    "print(f'fit time is {fit_time} and Predict time is {predict_time}')\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print(auc(fpr, tpr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Conclusion : The performance with all features is better than a single feature - digit%\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
